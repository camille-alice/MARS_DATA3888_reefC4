---
title: "Group Assignment"
author: "Patrick Chang"
date: "28/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(dplyr)
library(sf)
library(tidyverse)
library(car)
library(Metrics)
library(caret)
library(lme4)

reef_geomorphic = st_read("C:/Users/patri/OneDrive/Desktop/DATA3888/MARS_DATA3888_reefC4/Data/reef_geomorphic_joined_all.gpkg")
reef_geomorphic = reef_geomorphic %>% 
  as.data.frame() %>%
  mutate(Date = as.Date(Date, "%d-%b-%y")) %>%
  mutate(Depth = as.numeric(Depth)) %>%
  filter(Depth <= 15) # as per Allen Coral Atlas specs
```

#Data Cleaning
```{r}
#Most recent entry

#Select several attributes for our model
reef_recent = reef_geomorphic %>%
  select(Reef.ID, Longitude.Degrees, Latitude.Degrees, Date, SSTA_Frequency_Standard_Deviation, Depth, Diversity, class,Average_bleaching) %>% 
  mutate(SSTA_Frequency_Standard_Deviation = as.numeric(SSTA_Frequency_Standard_Deviation),
         Average_bleaching = as.numeric(Average_bleaching),
         Depth = as.numeric(Depth), 
         Diversity = as.numeric(Diversity)) %>%
  group_by(Reef.ID) %>% filter(Date == max(Date))


#Rugosity
reef_recent["rugosity"] <- ifelse(reef_recent$class == "Reef Slope" | reef_recent$class == "Outer Reef Flat","High",
                                 ifelse(reef_recent$class == "Sheltered Reef Slope" | reef_recent$class == "Reef Crest" | reef_recent$class == "Back Reef Slope","Medium","Low"))

#For knn,svm and rf change the rugosity to 1,2,3
reef_recent["num_rugosity"] <- ifelse(reef_recent$rugosity == "High", 3,
                                     ifelse(reef_recent$rugosity == "Medium",2,1))


#bleached or not bleached
reef_recent["bleached"] <- ifelse(reef_recent$Average_bleaching > 0,1,0)
reef_recent$bleached <- as.factor(reef_recent$bleached)


#Remove NA
reef_final <- reef_recent %>% drop_na()


#Binomial regression
reef_model <- glm(formula = bleached ~ Longitude.Degrees + Latitude.Degrees + SSTA_Frequency_Standard_Deviation + Depth + Diversity + rugosity, data = reef_final, family = binomial)

summary(reef_model)

```


##Binomial regression
```{r}

#Cross-validation using binomial
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","bleached","num_rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

cvK = 10 # number of CV folds
cv_50acc5_bin = c()
cv_acc_bin = c()
n_sim = 50

fitres_bin = factor()
y_bin = c()

start_time = Sys.time()
for (i in 1:n_sim){
  cvSets = cvTools::cvFolds(nrow(X), cvK)  # permute all the data, into 5 folds
  cv_acc_bin = c()
  
  for (j in 1:cvK) {
    test_id = cvSets$subsets[cvSets$which == j]
    X_test = X[test_id, ]
    X_train = X[-test_id, ]
    y_test = y[test_id]
    y_train = y[-test_id]
    
    X_train = X_train %>% mutate(bleached = y_train)
    
    lm = glm(formula = bleached ~ Longitude.Degrees + Latitude.Degrees + SSTA_Frequency_Standard_Deviation + Depth + Diversity + rugosity, data = X_train,family = binomial)
    predicted_outcomes = predict.glm(lm, X_test, type = "response")
    
    predicted_outcomes = ifelse(predicted_outcomes > 0.5, 1, 0)
    
    fitres_bin = append(fitres_bin, predicted_outcomes)
    y_bin = append(y_bin, y_test)
    
    cv_acc_bin[j] = mean(predicted_outcomes == y_test)
    
  }
  cv_50acc5_bin = append(cv_50acc5_bin, mean(cv_acc_bin))
  
}
end_time = Sys.time()
bin_cv_time = end_time-start_time
bin_cv_time

bin_mean = mean(cv_50acc5_bin)
bin_sd = sd(cv_50acc5_bin)

bin_mean
bin_sd

#F1-score for full binomial
bin_cf = confusionMatrix(as.factor(fitres_bin), y_bin,
                mode = "everything",
                positive="1")

bin_cf

#Boxplot for full binomial model accuracy
boxplot(cv_50acc5_bin, ylab = 'CV Accuracy' ,xlab = 'Binomial Regression' , main = 'Accuracy of Binomial Regression in CV')

```

##Binomial regression with selected variables

```{r}
#Variable selection for binomial regression, we decide to drop rugosity
step_model_reef = step(reef_model, trace = 0)
summary(step_model_reef)

#Cross Validation using selected model
set.seed(3888)

#reef without "bleached" and other useless attributes
#Add class to the variable/attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","bleached","num_rugosity","rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

cvK = 10 # number of CV folds
cv_50acc5_sel = c()
cv_acc_sel = c()
n_sim = 50 

fitres_sel = factor()
y_sel = c()

for (i in 1:n_sim){
  cvSets = cvTools::cvFolds(nrow(X), cvK)  # permute all the data, into 5 folds
  cv_acc_sel = c()
  
  for (j in 1:cvK) {
    test_id = cvSets$subsets[cvSets$which == j]
    X_test = X[test_id, ]
    X_train = X[-test_id, ]
    y_test = y[test_id]
    y_train = y[-test_id]
    
    X_train = X_train %>% mutate(bleached = y_train)
    
    slm = glm(formula = bleached ~ Latitude.Degrees + SSTA_Frequency_Standard_Deviation + Depth + Diversity, data = X_train,family = binomial)
    predicted_outcomes = predict.glm(slm, X_test, type = "response")
    
    predicted_outcomes = ifelse(predicted_outcomes > 0.5, 1, 0)
    
    
    fitres_sel = append(fitres_sel,predicted_outcomes)
    y_sel = append(y_sel, y_test)
    
    cv_acc_sel[j] = mean(predicted_outcomes == y_test)
    
  }
  cv_50acc5_sel = append(cv_50acc5_sel, mean(cv_acc_sel))
  
}

sel_mean = mean(cv_50acc5_sel)
sel_sd = sd(cv_50acc5_sel)

sel_mean
sel_sd

#F1-Score for selected binomial
bin_sel_cf = confusionMatrix(as.factor(fitres_sel), y_sel,
                mode = "everything",
                positive="1")

bin_sel_cf
#Boxplot for selected binomial model accuracy
boxplot(cv_50acc5_sel, ylab = 'CV Accuracy' ,xlab = 'Selected Binomial Regression' , main = 'Accuracy of Selected Binomial Regression Without Rugosity in CV')
```


#Naive Bayes

```{r}
#Do Naive Bayes model
#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","bleached","num_rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

set.seed(3888)
cv_acc50_NB = c()  # initialise results vector
cv_acc_NB = c()
K = 10

fitres_NB = factor()
y_NB = c()

start_time = Sys.time()
for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
      test_id = cvSets$subsets[cvSets$which == j]
      X_test = X[test_id, ]
      X_train = X[-test_id, ]
      y_test = y[test_id]
      y_train = y[-test_id]
      
      X_train = X_train %>% mutate(bleached = y_train)
      
      nB = e1071::naiveBayes(formula = bleached ~ SSTA_Frequency_Standard_Deviation + Depth + Diversity + rugosity, data = X_train)
      predicted_outcomes = predict(nB, X_test)
      
  
      fitres_NB = append(fitres_NB, predicted_outcomes)
      y_NB = append(y_NB, y_test)
  
      cv_acc_NB[j] = mean(predicted_outcomes == y_test)
    }
    
    cv_acc50_NB <- append(cv_acc50_NB, mean(cv_acc_NB))
}
end_time = Sys.time()
nb_cv_time = end_time-start_time

nb_cv_time

nb_mean = mean(cv_acc50_NB)
nb_sd = sd(cv_acc50_NB)

nb_mean
nb_sd

#F1-score for Naive Bayes
nb_cf = confusionMatrix(fitres_NB, y_NB,
                mode = "everything",
                positive="1")
nb_cf

#Boxplot for Naive bayes  model
boxplot(cv_acc50_NB, ylab = 'CV Accuracy' ,xlab = 'Naive Bayes' , main = 'Accuracy of Naive Bayes in CV')
```

#Naive Bayes without rugosity
```{r}
#Do Naive Bayes model without rugosity
#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","bleached","num_rugosity","rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

set.seed(3888)
cv_acc50_NB_WO = c()  # initialise results vector
cv_acc_NB_WO = c()
K = 10

fitres_NB_WO = factor()
y_NB_WO = c()

for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
      test_id = cvSets$subsets[cvSets$which == j]
      X_test = X[test_id, ]
      X_train = X[-test_id, ]
      y_test = y[test_id]
      y_train = y[-test_id]
      
      X_train = X_train %>% mutate(bleached = y_train)
      
      nB = e1071::naiveBayes(formula = bleached ~ SSTA_Frequency_Standard_Deviation + Depth + Diversity, data = X_train)
      predicted_outcomes = predict(nB, X_test)
      
  
      fitres_NB_WO = append(fitres_NB_WO, predicted_outcomes)
      y_NB_WO = append(y_NB_WO, y_test)
  
      cv_acc_NB_WO[j] = mean(predicted_outcomes == y_test)
    }
    
    cv_acc50_NB_WO <- append(cv_acc50_NB_WO, mean(cv_acc_NB_WO))
}

nb_mean_WO = mean(cv_acc50_NB_WO)
nb_sd_WO = sd(cv_acc50_NB_WO)

nb_mean_WO
nb_sd_WO

#F1-score for Naive Bayes
nb_cf_WO = confusionMatrix(fitres_NB_WO, y_NB_WO,
                mode = "everything",
                positive="1")
nb_cf_WO


#Boxplot for Naive bayes  model
boxplot(cv_acc50_NB_WO, ylab = 'CV Accuracy' ,xlab = 'Naive Bayes' , main = 'Accuracy of Naive Bayes Without Rugosity in CV')
```


#K-nearest Neighbour

```{r}
#Do KNN using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
save_X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity"))
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()
save_y = y

fitres_knn = factor()
y_knn = c()

cv_acc50_knn = c()  # initialise results vector
cv_acc_knn = c()
K = 10

start_time = Sys.time()
for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        fit = class::knn(train = X_train, test = X_test, cl = y_train, k = 5)
        cv_acc_knn[j] = mean(fit == y_test)
        fitres_knn = append(fitres_knn, fit)
        y_knn = append(y_knn, y_test)
    }
    
    cv_acc50_knn <- append(cv_acc50_knn, mean(cv_acc_knn))
}
end_time = Sys.time()
knn_cv_time = end_time-start_time

knn_cv_time

knn_mean = mean(cv_acc50_knn)
knn_sd = sd(cv_acc50_knn)

knn_mean
knn_sd

#F1-score for knn
knn_cf = confusionMatrix(as.factor(fitres_knn), y_knn,
                mode = "everything",
                positive="1")
knn_cf

#Boxplot for KNN model
boxplot(cv_acc50_knn, ylab = 'CV Accuracy' ,xlab = 'K-Nearest Neighbour' , main = 'Accuracy of K-Nearest Neighbour in CV')
```

#K Nearest Neighbour without rugosity

```{r}
#Do KNN using the selected variable 
set.seed(3888)

#reef without "bleached","rugosity" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity","num_rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

fitres_knn_WO = factor()
y_knn_WO = c()

cv_acc50_knn_WO = c()  # initialise results vector
cv_acc_knn_WO = c()
K = 10

for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        fit = class::knn(train = X_train, test = X_test, cl = y_train, k = 5)
        cv_acc_knn_WO[j] = mean(fit == y_test)
        fitres_knn_WO = append(fitres_knn_WO, fit)
        y_knn_WO = append(y_knn_WO, y_test)
    }
    
    cv_acc50_knn_WO <- append(cv_acc50_knn_WO, mean(cv_acc_knn_WO))
}

knn_mean_WO = mean(cv_acc50_knn_WO)
knn_sd_WO = sd(cv_acc50_knn_WO)

knn_mean_WO
knn_sd_WO

#F1-score for knn
knn_cf_WO = confusionMatrix(as.factor(fitres_knn_WO), y_knn_WO,
                mode = "everything",
                positive="1")
knn_cf_WO

#Boxplot for KNN model
boxplot(cv_acc50_knn_WO, ylab = 'CV Accuracy' ,xlab = 'K-Nearest Neighbour' , main = 'Accuracy of K-Nearest Neighbour Without Rugosity in CV')
```


#Random Forest

```{r}
#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

#Do random forest
set.seed(3888)
cv_acc50_rf = c()  # initialise results vector
cv_acc_rf = c()
K = 10

fitres_rf = factor()
y_rf = c()

start_time = Sys.time()
for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        rf_res <- randomForest::randomForest(x = X_train, y = as.factor(y_train))
        fit <- predict(rf_res, X_test)
        cv_acc_rf[j] = mean(fit == y_test)
        fitres_rf = append(fitres_rf, fit)
        y_rf = append(y_rf, y_test)
    }
    
    cv_acc50_rf <- append(cv_acc50_rf, mean(cv_acc_rf))
}
end_time = Sys.time()
rf_cv_time = end_time-start_time

rf_cv_time

rf_mean = mean(cv_acc50_rf)
rf_sd = sd(cv_acc50_rf)

rf_mean
rf_sd

#F1-score for rf
rf_cf = confusionMatrix(as.factor(fitres_rf), y_rf,
                mode = "everything",
                positive="1")
rf_cf

#Boxplot for Random forest model
boxplot(cv_acc50_rf, ylab = 'CV Accuracy' ,xlab = 'Random Forest' , main = 'Accuracy of Random Forest in CV')
```

#Random Forest Without Rugosity

```{r}
#reef without "bleached","rugosity" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity","num_rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

#Do random forest
set.seed(3888)
cv_acc50_rf_WO = c()  # initialise results vector
cv_acc_rf_WO = c()
K = 10

fitres_rf_WO = factor()
y_rf_WO = c()

for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        rf_res <- randomForest::randomForest(x = X_train, y = as.factor(y_train))
        fit <- predict(rf_res, X_test)
        cv_acc_rf_WO[j] = mean(fit == y_test)
        fitres_rf_WO = append(fitres_rf_WO, fit)
        y_rf_WO = append(y_rf_WO, y_test)
    }
    
    cv_acc50_rf_WO <- append(cv_acc50_rf_WO, mean(cv_acc_rf_WO))
}

rf_mean_WO = mean(cv_acc50_rf_WO)
rf_sd_WO = sd(cv_acc50_rf_WO)

rf_mean_WO
rf_sd_WO

#F1-score for rf
rf_cf_WO = confusionMatrix(as.factor(fitres_rf_WO), y_rf_WO,
                mode = "everything",
                positive="1")
rf_cf_WO

#Boxplot for Random forest model
boxplot(cv_acc50_rf_WO, ylab = 'CV Accuracy' ,xlab = 'Random Forest' , main = 'Accuracy of Random Forest Without Rugosity in CV')

```


#SVM model

```{r}
#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

#Do SVM model
set.seed(3888)
cv_acc50_svm = c()  # initialise results vector
cv_acc_svm = c()
K = 10

fitres_svm = factor()
y_svm = c()

start_time = Sys.time()
for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        ## SVM
        svm_res <- e1071::svm(x = X_train, y = as.factor(y_train))
        fit <- predict(svm_res, X_test)
        cv_acc_svm[j] = mean(fit == y_test)
        fitres_svm = append(fitres_svm, fit)
        y_svm = append(y_svm, y_test)
    }
    
    cv_acc50_svm <- append(cv_acc50_svm, mean(cv_acc_svm))
}
end_time = Sys.time()
svm_cv_time = end_time-start_time

svm_cv_time

svm_mean = mean(cv_acc50_svm)
svm_sd = sd(cv_acc50_svm)

svm_mean
svm_sd

#F1-score for svm
svm_cf = confusionMatrix(as.factor(fitres_svm), y_svm,
                mode = "everything",
                positive="1")
svm_cf

#Boxplot for SVM  model
boxplot(cv_acc50_svm, ylab = 'CV Accuracy' ,xlab = 'Support Vector Machine' , main = 'Accuracy of Support Vector Machine in CV')
```

#SVM model without Rugosity

```{r}
#reef without "bleached","rugosity" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity","num_rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()
#Do SVM model
set.seed(3888)
cv_acc50_svm_WO = c()  # initialise results vector
cv_acc_svm_WO = c()
K = 10

fitres_svm_WO = factor()
y_svm_WO = c()

for (i in 1:50){
    
    cvSets = cvTools::cvFolds(nrow(X), K) 

    for (j in 1:K) {
        test_id = cvSets$subsets[cvSets$which == j]
        X_test = X[test_id, ]
        X_train = X[-test_id, ]
        y_test = y[test_id]
        y_train = y[-test_id]
        ## SVM
        svm_res <- e1071::svm(x = X_train, y = as.factor(y_train))
        fit <- predict(svm_res, X_test)
        cv_acc_svm_WO[j] = mean(fit == y_test)
        fitres_svm_WO = append(fitres_svm_WO, fit)
        y_svm_WO = append(y_svm_WO, y_test)
    }
    
    cv_acc50_svm_WO <- append(cv_acc50_svm_WO, mean(cv_acc_svm_WO))
}

svm_mean_WO = mean(cv_acc50_svm_WO)
svm_sd_WO = sd(cv_acc50_svm_WO)

svm_mean_WO
svm_sd_WO

#F1-score for svm
svm_cf_WO = confusionMatrix(as.factor(fitres_svm_WO), y_svm_WO,
                mode = "everything",
                positive="1")

svm_cf_WO

#Boxplot for SVM  model
boxplot(cv_acc50_svm_WO, ylab = 'CV Accuracy' ,xlab = 'Support Vector Machine' , main = 'Accuracy of Support Vector Machine without Rugosity in CV')
```

#Little summary
```{r}

#Running time, scalability different size of the data
#Stability, standard deviation of the box
#Interprebality just how we word the model

#Conclusion Summary
#Full Binomial model gave 0.6498735 accuracy, f1 score 0.20677, sd:0.002481738
#Naive Bayes gave 0.6247871 accuracy, f1 score 0.33155, sd: 0.002666694
#KNN gave 0.6587548 accuracy, f1 score 0.4596, sd: 0.005003624
#Support Vector Machine gave 0.6647083 accuracy, f1 score 0.25099, sd: 0.003176242
#Random forest gave 0.7158592 accuracy, f1 score 0.5632, sd: 0.004287599

#Without rugosity
#Selected Binomial model gave 0.6447377 accuracy (w/o rugosity), f1 score 0.20237, sd:0.001997279
#Naive Bayes gave 0.6278599 accuracy, f1 score 0.32603, sd:0.002424676
#KNN gave 0.6689606 accuracy, f1 score 0.4841, sd:0.005267227
#Support Vector Machine gave 0.6600222 accuracy, f1 score 0.27592, sd:0.003717103
#Random forest gave 0.70576 accuracy, f1 score 0.5515, sd:0.00580881
```

#Time all the algorithm

```{r}
#Time selected binomial model

#Do KNN using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","num_rugosity","rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

#take last 1000 data as our train data
X_train = tail(X,1000)
y_train = tail(y,1000)
X_train = X_train %>% mutate(bleached = y_train)

start_time = Sys.time()
slm = glm(formula = bleached ~ Longitude.Degrees + Latitude.Degrees + SSTA_Frequency_Standard_Deviation + Depth + Diversity, data = X_train,family = binomial)
end_time = Sys.time()
diff_time = end_time - start_time

time_bin = c()
i = 100
while (i < 1000) {
  Sys.sleep(1)
  #take first i data as our test data
  X_test = head(X,i)
  y_test = head(y,i)
  start_time = Sys.time()
  predicted_outcomes = predict.glm(slm, X_test, type = "response")
  predicted_outcomes = ifelse(predicted_outcomes > 0.5, 1, 0)
  end_time = Sys.time()
  i = i + 100 
  end_time = Sys.time()
  diff_time = end_time-start_time
  time_bin = append(time_bin,diff_time)
}


final_time_bin = c()
for (time in time_bin){
  time_add = time + train_diff
  final_time_bin = append(final_time_bin,time_add)
}

final_time_bin
```


```{r}
#Time Naive Bayes model

#Do NB using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","num_rugosity","rugosity"))

y = reef_ungroup %>% select(bleached) %>% pull()

#train the model
#take last 1000 data as our train data
X_train = tail(X,1000)
y_train = tail(y,1000)
X_train = X_train %>% mutate(bleached = y_train)

start_time = Sys.time()
nB = e1071::naiveBayes(formula = bleached ~ SSTA_Frequency_Standard_Deviation + Depth + Diversity, data = X_train)
end_time = Sys.time()

train_diff = end_time - start_time

time_nb = c()
i = 100
while (i < 1000) {
  Sys.sleep(1)
  #take first i data as our test data
  X_test = head(X,i)
  y_test = head(y,i)
  start_time = Sys.time()
  predicted_outcomes = predict(nB, X_test)
  end_time = Sys.time()
  i = i + 100
  diff_time = end_time-start_time
  time_nb = append(time_nb,diff_time)
}

final_time_nb = c()
for (time in time_nb){
  time_add = time + train_diff
  final_time_nb = append(final_time_nb,time_add)
}

final_time_nb
```


```{r}
#Time KNN model

#Do KNN using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

time_knn = c()

i = 100
while (i < 1000) {
  Sys.sleep(1)
  #take last 1000 data as our train data
  X_train = tail(X,1000)
  y_train = tail(y,1000)
  #take first i data as our test data
  X_test = head(X,i)
  y_test = head(y,i)
  start_time = Sys.time()
  fit = class::knn(train = X_train, test = X_test, cl = y_train, k = 5)
  end_time = Sys.time()
  i = i + 100
  diff_time = end_time-start_time
  time_knn = append(time_knn,diff_time)
}

time_knn
```


```{r}
#Time RF model

#Do RF using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity","num_rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

time_rf = c()
i = 100
#time the training the model
start_time = Sys.time()
#take last 1000 data as our train data
X_train = tail(X,1000)
y_train = tail(y,1000)
rf_res <- randomForest::randomForest(x = X_train, y = as.factor(y_train))
end_time = Sys.time()
train_diff = end_time - start_time

while (i < 1000) {
  Sys.sleep(1)
  #take first i data as our test data
  X_test = head(X,i)
  y_test = head(y,i)
  start_time = Sys.time()
  fit <- predict(rf_res, X_test)
  end_time = Sys.time()
  i = i + 100
  diff_time = end_time-start_time
  time_rf = append(time_rf,diff_time)
}

final_time_rf = c()
for (time in time_rf){
  time_add = time + train_diff
  final_time_rf = append(final_time_rf,time_add)
}

final_time_rf
```


```{r}
#Time SVM model

#Do svm using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()
X = reef_ungroup %>% select(-c("Average_bleaching","bleached","Reef.ID","Date","class","rugosity","num_rugosity")) %>% scale()

y = reef_ungroup %>% select(bleached) %>% pull()

time_svm = c()
i = 100

#take last 1000 data as our train data
X_train = tail(X,1000)
y_train = tail(y,1000)
#time the training the model
start_time = Sys.time()
svm_res <- e1071::svm(x = X_train, y = as.factor(y_train))
end_time = Sys.time()

train_diff = end_time-start_time

while (i < 1000) {
  Sys.sleep(1)
  #take first i data as our test data
  X_test = head(X,i)
  y_test = head(y,i)
  start_time = Sys.time()
  fit <- predict(svm_res, X_test)
  end_time = Sys.time()
  i = i + 100
  diff_time = end_time-start_time
  time_svm = append(time_svm,diff_time)
}

final_time_svm = c()
for (time in time_svm){
  time_add = time + train_diff
  final_time_svm = append(final_time_svm,time_add)
}

final_time_svm
```

```{r}
#lineplot
i = 100
num_record = c()
while (i < 1000){
  num_record = append(num_record,i)
  i = i + 100
}
plot(num_record,final_time_bin, type="l", col="green", lwd=5, pch=15, xlab="number of test data", ylab="time",ylim=range(final_time_bin,time_knn,final_time_nb,final_time_rf,final_time_svm))
lines(num_record, time_knn, type="l", col="red", lwd=2, pch=19)
lines(num_record, final_time_rf, type="l", col="blue", lwd=2, pch=19)
lines(num_record, final_time_nb, type="l", col="yellow", lwd=2, pch=19)
lines(num_record, final_time_svm, type="l", col="pink", lwd=2, pch=19)
title("Time of all models")
legend(x = "topright", legend = c("Binomial","KNN","RF","NB","SVM"),lty = c(1, 1,1,1,1), col=c("green","red","blue","yellow","pink"))
```

# Testing multicollinearity and independent test

```{r}
#Binomial regression
reef_model <- glm(formula = bleached ~ Longitude.Degrees + Latitude.Degrees + SSTA_Frequency_Standard_Deviation + Depth + Diversity + rugosity, data = reef_final, family = binomial)

#Do VIF 
vif_result <- vif(reef_model)
vif_result
#Based on the VIF test, it suggest that there is no severe multicollinearity problem between variables that we chose

c_mat = table(reef_final$bleached,reef_final$rugosity)
# Expected contingency table
eij = data.frame(chisq.test(c_mat, correct = FALSE)$expected %>%
  round(2)) %>% tibble()

# There is no expected cell <= 5, we going to use chi-square test
p_value = chisq.test(c_mat, correct = FALSE)$p.value
p_value

#the null hypothesis: there is no association between bleaching and rugosity
#the alternate hypothesis: there is association between bleaching and rugosity

#Since our p-value more than 0.05 we retain null hypothesis and conclude that there is no association between bleaching and rugosity but our p-value is slightly above 0.05 (0.061645), so the evidence of retaining the null hypotheis are quite weak.
```

#Fine tuning for Knn

```{r}
#Do KNN using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()

dataset = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","rugosity","num_rugosity"))

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
set.seed(3333)
knn_fit <- train(bleached ~., data = dataset, method = "knn",
  trControl=trctrl,
  metric = "Accuracy",
  tuneGrid = data.frame(k = seq(1,100,by = 1)))

knn_fit
```

# Fine tuning for random forest
```{r}
#Do RF using the selected variable 
set.seed(3888)

#reef without "bleached" and other useless attributes
reef_ungroup = reef_final %>% ungroup()

dataset = reef_ungroup %>% select(-c("Average_bleaching","Reef.ID","Date","class","rugosity","num_rugosity"))

# Ntree Search
control <- trainControl(method="repeatedcv", number=10, repeats=10, search="grid")
tunegrid <- expand.grid(.mtry=c(5))
modellist <- list()
for (ntree in c(500,1000, 1500, 2000, 2500)) {
	set.seed(3888)
	fit <- train(bleached~., data=dataset, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
	key <- toString(ntree)
	modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
```


# Saving results to file

```{r}
save(cv_50acc5_bin, cv_acc50_NB, cv_acc50_knn, cv_acc50_rf, cv_acc50_svm,
     cv_50acc5_sel, cv_acc50_NB_WO, cv_acc50_knn_WO, cv_acc50_rf, cv_acc50_svm_WO,
     bin_cf, nb_cf, knn_cf, rf_cf, svm_cf,
     bin_sel_cf, nb_cf_WO, knn_cf_WO, rf_cf_WO, svm_cf_WO,
     bin_mean, nb_mean, knn_mean, rf_mean, svm_mean,
     sel_mean, nb_mean_WO, knn_mean_WO, rf_mean_WO, svm_mean_WO,
     bin_sd, nb_sd, knn_sd, rf_sd, svm_sd,
     sel_sd, nb_sd_WO, knn_sd_WO, rf_sd_WO, svm_sd_WO,
     time_bin, time_nb, time_knn, time_rf, time_svm,
     save_X, save_y,
     file = "model_results.rds")
```

